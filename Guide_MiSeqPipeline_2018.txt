June 1st, 2018

###################################
Before starting you need to install:
# python 3
# biopython
# PEAR
# SWARM
# ncbi_BLAST+ (not needed in the last version)
# Vsearch
# EMBOSS-6.6.0
# mafft
# raxml (not needed if you build your tree through CIPRES)
# figtree
# seaview (not needed, only for looking at your alignment)
####################################

INSTALLATION in terminal:
## homebrew (reinstall homebrew fix a lot of issues)
$ ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"

## git and automake
$ brew install git
$ brew install automake
$ brew install wget

## python 3
$ brew install python3
$ brew link --overwrite python3


## install biopython for python3
$ python3 -m pip install --upgrade pip
$ python3 -m pip install numpy
$ python3 -m pip install scipy
$ python3 -m pip install pandas
$ python3 -m pip install biopython

## install PEAR (Paired-end read merger)
Download from https://www.h-its.org/downloads/pear-academic/
move the file to your installation folder (here document/softwares/).
$ cd document/softwares/
$ tar -xzvf pear-src-0.9.11
$ autoreconf -i
$ ./configure
$ make
$ sudo make install


## install SWARM
$ git clone https://github.com/torognes/swarm.git
move the file to your installation folder (located in your root).
$ cd document/softwares/swarm/src/
$ make

## ncbi_BLAST+
go here ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/ncbi-blast-2.7.1+.dmg and follow the instruction


## vsearch (https://github.com/torognes/vsearch) 
$ wget https://github.com/torognes/vsearch/archive/v2.8.0.tar.gz
or download everything from https://github.com/torognes/vsearch (green button Clone or download at the right corner)
$ tar xzf v2.8.0.tar.gz
$ cd vsearch-2.8.0
$ ./autogen.sh
$ ./configure
$ make
$ make install  # as root or sudo make install

## EMBOSS
Go to this page to download EMBOSS ftp://emboss.open-bio.org/pub/EMBOSS/
Download emboss-latest.tar.gz
move the file to your installation folder.
$ cd your installation folder
$ tar -xzvf emboss-latest.tar.gz
$ cd EMBOSS-6.6.0 
$ ./configure —prefix=/usr/local/emboss
$ make -j 4 (4 in the number of thread of your computer)
$ make install

## MAFFT
$ brew install mafft
$ brew link --overwrite mafft

## RAxML
Go to https://github.com/stamatak/standard-RAxML and download everything (green button Clone or download at the right corner)
move the folder to your installation folder.
$ cd document/softwares/standard-RAxML-master/
$ make -f Makefile.AVX2.PTHREADS.gcc

## Figtree
go to http://tree.bio.ed.ac.uk/software/figtree/
download the last version of FigTree here FigTree v1.4.3.dmg (right side)
double click on the dmg and follow instruction

## seaview:
go to http://doua.prabi.fr/software/seaview
download the MacOS version and follow instruction

## path_update
$ cd
$ open .bash_profile
if you do not have a .bash_profile file
$ touch .bash_profile 
$ open .bash_profile

Add to the file
export PATH=/folder where installation happen (something like /Users/katzlab/document/softwares/):/${PATH}

for example:
export PATH=/Users/katzlab/document/softwares/pear-0.9.11-linux-x86_64/bin/:/Users/katzlab/document/softwares/swarm/bin/:/Users/katzlab/document/softwares/vsearch-2.7.1-macos-x86_64/bin/:/Users/katzlab/document/softwares/standard-RAxML-master/:${PATH}

###########################################################
Pipeline Guide

Prepare your data and folders:
0- keep the same folders and files structure from the repository or the script will crash
1- Create a folder named Rawdata with all your MiSeq sequence files (e.g. LAKM1_To.1.2_S1_L001_R1.fastq.gz, LAKM1_To.1.2_S1_L001_R2.fastq.gz)
	You can use the script movefile.py to create this folder
2- Create a file with your sample code and sample name (a file named List_samples.txt containing: LKM# (tab) samplename ) \n '
	You can use excel to create this file and save as a Tab Delimited Text (.txt) file
	So far, the List_samples.txt file includes all the samples. Delete the samples you are not interested in.
3- Copy the script folder, SAR_db folder and the 3 scripts named MiSeq_pipeline_SAR_SWARM_part(1,2 and 3).py from this Google Drive folder and add all in the folder where you save the samplelist.txt and the rawdata folder (MiSeq_folder).
4- Open the script 6 (in Miseq_scripts folder, named 6_BLASTn_V2.py).
	Replace the XXX by the email address you are using for your NCBI account => Entrez.email = "XXX@smith.edu"
	If you don't an NCBI account, you should create one by going to this ncbi webpage (https://www.ncbi.nlm.nih.gov/account/register/?back_url=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fbioproject&partners-uri=cms:/account/partners)
	__Update__: the new version use Vsearch, so you do not need to do this step of NCBI account.

Running the pipeline:
	In terminal:
		$ cd Amplicon_MiSeq_pipeline
		for step 1:
		$ python3 MiSeq_pipeline_SAR_SWARM_part1.py List_sample.txt
		for step 2:
		$ python3 MiSeq_pipeline_SAR_SWARM_part2.py List_sample.txt
		for step 3:
		$ python3 MiSeq_pipeline_SAR_SWARM_part3.py List_sample.txt dataname RAxML_labelledTree_masked_<project>.tre
		
	=> dataname (e.g. M00763) it's the first code of the sequences name in your convertPEARfiles: >M00763:221:000000000-BP36R:1:1101:14475:1627 1:N:0:AGGCAGAA+AGAGTAGA.
	=> RAxML_labelledTree_masked_<project>.tre is the tree run at the end of step 2. You hsould has also a tree with only the outgroup named RAxML_labelledTree_masked_<project>_outgroup.tre
				

What is happening in each script:
1- The script MiSeq_pipeline_SAR_SWARM_part1.py will:
	a- merge your forward and reverse reads using PEAR (Paired-End Read merger) and convert the fastq files in fasta files. (PEAR folder) **=> update PEAR parameters if you use another primer set**
	b- create a file name readpersample.txt. This file contains the name of your sample and the number of reads after PEAR. (ConvertPEAR folder)
2- The script MiSeq_pipeline_SAR_SWARM_part2.py will:
	a- Pick OTUs with SWARM (in OTUs folder, you will find a SWARM_postout.fas files. It's the sequences of your SWARM OTUs)
	b- Create an OTU table i.e. a table with the proportion of each SWARM OTU for each sample. (in OTUs folder, OTUtable.txt file. You can open the file in excel and have fun analyzing your data).
	c- Remove chimera using Uchime3_denovo implemented in Vsearch
	d- Remove OTUs too dissimilar to the most abundant OTU using Water implemented in EMBOSS
	e- BLAST SWARM OTU against SAR database (or you homemade db). (in the folder Taxonomic_assignment, you will find two file: "Blast_result_renamed.txt" with the BLAST results and the classification and "no_BLAST_result.txt" containing all SWARM OTUs without BLAST results for the cutoff you used)
	f- Create an alignment of your OTU and SAR reference from SAR_db folder (or your homemade db) and remove column with more than 75% empty characters.
	(you will also find a temp folder. This folder is for troubleshooting. If you have not issue you can delete it.)
3- You have to built the tree for the next step:
	a- You can built the tree locally on your computer using the commandline: raxmlHPC-PTHREADS-AVX2 -f v -s OTUseq_nosingleton_nochimeras_nocont_BLASTed_TA_masked.fas -m GTRGAMMAI -t SSU_SAR_EUK_v14.3_RAxML_constraint_rooted.tre -n <name of the output> -T -1
	b- This tree can also be run through CIPRES REST API (CRA) with this commandline: 
	$ export URL=https://cipresrest.sdsc.edu/cipresrest/v1
	$ export CRA_USER = your username on CIPRES
	$ export PASSWORD = you password on CIPRES
	$ export KEY= you key generater on CIPRES
	see https://www.phylo.org/restusers/documentation.action for more informations
	$ curl -u $CRA_USER:$PASSWORD -H cipres-appkey:$KEY $URL/job/$CRA_USER -F tool=RAXMLHPC8_REST_XSEDE -F vparam.select_analysis_=fv -F input.infile_=@./outputs/outgroup_removal/OTUseq_nosingleton_nochimeras_nocont_BLASTed_TA_masked.fas -F vparam.runtime_=168 -F vparam.dna_gtrcat_=GTRGAMMA -F vparam.invariable_=I -F input.treetop_=@./SAR_db/SSU_SAR_EUK_v14.3_RAxML_constraint_rooted.tre -F metadata.statusEmail=true
		A script is availabe to build your tree on CIPRES REST API (see SSU_Database_Builing, turn off line 26 and 27, and turn on line 29,30, and 31. Do not forget to add your reference tree (/SAR_db/SSU_SAR_EUK_v14.3_RAxML_constraint_rooted.tre for SAR primers)
	(i) OTUseq_nosingleton_nochimeras_nocont_BLASTed_TA_masked.fas is the alignment create at the end of the script 2
	(ii) SSU_SAR_EUK_v14.3_RAxML_constraint_rooted.tre is a reference tree from the SAR_db folder (or homemade tree).
4- Using Figtree, copy and paste the outgroup clade in a new tree.
	This step will help removing the outgroup OTUs from your dataset
5- The script MiSeq_pipeline_SAR_SWARM_part3.py will:
	a- Remove outgroup OTUs based on the tree
	b- Rarefy your samples to be able to compare them (this step take a while)
	c- Assign taxonomy by tree
	d- Built the final OTU table (OTUtable_ingroup.txt), which contains the Taxonomic assignment by BLAST (Btaxo…) and by Tree (Ttaxo), the number of read and occurrence of each OTU and the distribution in your samples.

Now you have your final files, you can explore your data. HAVE FUN !!
